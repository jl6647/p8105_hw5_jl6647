p8105_hw5_jl6647
================
Jiatong Li
2023-11-02

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.3     ✔ readr     2.1.4
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.0
    ## ✔ ggplot2   3.4.3     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.2     ✔ tidyr     1.3.0
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(rvest)
```

    ## 
    ## Attaching package: 'rvest'
    ## 
    ## The following object is masked from 'package:readr':
    ## 
    ##     guess_encoding

``` r
library(viridis)
```

    ## Loading required package: viridisLite

``` r
library(readr)
library(plotly)
```

    ## 
    ## Attaching package: 'plotly'
    ## 
    ## The following object is masked from 'package:ggplot2':
    ## 
    ##     last_plot
    ## 
    ## The following object is masked from 'package:stats':
    ## 
    ##     filter
    ## 
    ## The following object is masked from 'package:graphics':
    ## 
    ##     layout

``` r
library(broom)

knitr::opts_chunk$set(
    echo = TRUE,
    warning = FALSE,
    fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

## Problem 1

## Problem 2

``` r
file_names = list.files(path = "data", pattern = "csv", full.names = TRUE)
df = data.frame(file_name = file_names)
```

## Problem 3

We first test the efficacy of the function on $\mu=0$.

``` r
sim_mean_pvalue = function(mu, n = 30, sigma = 5) {
  sim_data = tibble(
    x = rnorm(n = 30, mean = mu, sd = sigma),
  )
  
  sim_data |>  
    t.test() |>  
    broom::tidy() |>  
    select(mu_hat = estimate, 
           p_value = p.value)
  
}

# To replicate 5000 times
sim_results_df = 
  expand_grid(
    true_mean = 0,
    iter = 1:5000
  ) |> 
  mutate(
    estimate_df = map(true_mean, sim_mean_pvalue)
  ) |> 
  unnest(estimate_df)
```

Repeat the process for μ=1,2,3,4,5,6 (also replicate 5000 times)

``` r
sim_results_df = 
  expand_grid(
    true_mean = c(1, 2, 3, 4, 5, 6),
    iter = 1:5000
  ) |> 
  mutate(
    estimate_df = map(true_mean, sim_mean_pvalue)
  ) |> 
  unnest(estimate_df) |> 
  select(-iter)
```

##### Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of μ on the x axis. Describe the association between effect size and power. Make a plot showing the average estimate of μ on the y axis and the true value of μ on the x axis.

``` r
sim_results_df |> 
  filter(p_value < 0.05) |> 
  group_by(true_mean) |> 
  summarise(power = n()/5000) |> 
  ggplot(aes(x = true_mean, y = power)) +
  geom_line() +
  geom_point() +
  geom_smooth() +
  theme_minimal() +
  labs(title = "Power vs. True value of μ", x = "True value of μ", y = "The power of the test")
```

    ## `geom_smooth()` using method = 'loess' and formula = 'y ~ x'

<img src="p8105_hw5_jl6647_files/figure-gfm/unnamed-chunk-5-1.png" width="90%" />
From the plot we can see that

``` r
sim_results_df |>  
  group_by(true_mean) |> 
  summarise(est_mean = mean(mu_hat)) |> 
  ggplot(aes(x = true_mean, y = est_mean)) +
  geom_line() +
  geom_point() +
  geom_smooth() +
  labs(title = "The average estimate value of μ vs. True value of μ", x = "True value of μ", y = "The average estimate value of μ")
```

    ## `geom_smooth()` using method = 'loess' and formula = 'y ~ x'

<img src="p8105_hw5_jl6647_files/figure-gfm/unnamed-chunk-6-1.png" width="90%" />

##### Make a second plot (or overlay on the first) the average estimate of μ̂ only in samples for which the null was rejected on the y axis and the true value of μ on the x axis. Is the sample average of μ̂ across tests for which the null is rejected approximately equal to the true value of μ? Why or why not?
